{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auther: Aditya Vora\n",
    "# Introduction\n",
    "\n",
    "This script contains the code to demonstrate how to fine tune the *C3D convolutional features* using theano and lasagne. We can use the pre-trained weights of the network trained on *sports-1m dataset* for any of the applications that we target.  C3D can be used as a general video feature and has shown strong performance. You can find more information in the paper [1].\n",
    "\n",
    "* [1]: Tran, Du, et al. \"Learning spatiotemporal features with 3d convolutional networks.\" 2015 IEEE International Conference on Computer Vision (ICCV). IEEE, 2015. http://vlg.cs.dartmouth.edu/c3d/c3d_video.pdf\n",
    "\n",
    "# Notes\n",
    "\n",
    "* Here we have tried to fine tune the *C3D convolutional features* for our target application which involves two classes which is *walking and running*. Since the original network was trained with caffe which is available on github (https://github.com/facebook/C3D), we here use the model c3d_model.pkl which is open source. The model is downloaded and stored in the *models* directory. \n",
    "\n",
    "* The c3d_helper.py module contains the helper function to build the c3d model and set the weights to the network. \n",
    "\n",
    "* The data used for training and validation is in lmdb format, created and stored in the data folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import general libraries \n",
    "import c3d_helper\n",
    "import cv2\n",
    "import os\n",
    "import lmdb\n",
    "import numpy as np\n",
    "from datum import Datum4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import theano libraries\n",
    "import theano \n",
    "import theano.tensor as T\n",
    "dtensor5 = theano.tensor.TensorType(theano.config.floatX, (False,)*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import lasagne libraries\n",
    "import lasagne\n",
    "from lasagne.layers import InputLayer, DenseLayer, NonlinearityLayer\n",
    "from lasagne.layers.dnn import Conv2DDNNLayer as ConvLayer\n",
    "from lasagne.layers import Pool2DLayer as PoolLayer\n",
    "from lasagne.nonlinearities import softmax\n",
    "from lasagne.utils import floatX\n",
    "from lasagne.regularization import regularize_network_params, l2\n",
    "from lasagne.init import Constant, GlorotUniform, GlorotNormal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The DataFetcher class have helper function for the input and output of data during the training and validation phase. The load_data member function is used in order to fetch the required data from the lmdb database which are stored in the data folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Datafetcher class for input and output of the data during training and validation\n",
    "class DataFetcher(object):\n",
    "    def __init__(self,database_name,video_shape,batch_size,dtype='float32'):\n",
    "        self.db_name = database_name\n",
    "        self.video_shape = video_shape\n",
    "        self.batch_size = batch_size\n",
    "        self.env = lmdb.open(database_name)\n",
    "        self.txn = self.env.begin()\n",
    "        self.cursor = self.txn.cursor()\n",
    "        self.cursor.first()\n",
    "        self.iterator = iter(self.cursor)\n",
    "        self.dtype = dtype\n",
    "        self.epoch = 0\n",
    "        \n",
    "    def load_data(self):\n",
    "        TT, HH, WW = self.video_shape\n",
    "        X = np.empty((self.batch_size,3) + self.video_shape,dtype=self.dtype)\n",
    "        y = np.empty((self.batch_size,),dtype=self.dtype)\n",
    "        crossed_epoch = False\n",
    "        for n in xrange(self.batch_size):\n",
    "            try:\n",
    "                key,value = next(self.iterator)\n",
    "            except StopIteration:\n",
    "                self.cursor.first() \n",
    "                self.iterator = iter(self.cursor)\n",
    "                crossed_epoch = True\n",
    "                self.epoch += 1\n",
    "                key,value = next(self.iterator)\n",
    "                \n",
    "            datum = Datum4D.fromstring(value)\n",
    "            X[n] = datum.array\n",
    "            y[n] = datum.label\n",
    "                \n",
    "        return X, y, crossed_epoch\n",
    "                \n",
    "    def __del__(self):\n",
    "        self.txn.commit()\n",
    "        self.env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Test function to check whether the data flow is appropriate from the lmdb database. It tries to fetch a batch \n",
    "of data from the lmdb database and displays the frame of one of the clip in the batch.\n",
    "\"\"\" \n",
    "def test():\n",
    "    import time\n",
    "    import matplotlib.pyplot as plt    \n",
    "    db = \"./data/ucf-val.lmdb/\"\n",
    "    shape = (16,112,112)\n",
    "    fetcher = DataFetcher(db,shape,60)\n",
    "    tic = time.time()\n",
    "    X, y, _ = fetcher.load_data()\n",
    "    toc = time.time()\n",
    "    im = X[12,:,15].transpose(1,2,0) + 127.0\n",
    "    %matplotlib inline\n",
    "    plt.imshow(im.astype('uint8'))\n",
    "    print \"Retrieved %d videos in %0.4f milliseconds\" % (X.shape[0],1000*(toc-tic))\n",
    "    print \"Average retrieval time: %0.3f ms\" % (1000*(toc-tic)/X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build the model and load the weights from the pre-trained model. \n",
    "net = c3d.build_model()\n",
    "c3d.set_weights(net['prob'],'./models/c3d_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The below block of code below serves our purpose of fine-tuning the network. As we can see we are replacing the final layer of the network which have 437 classes of *sports-1m* dataset with our purpose which involves classifying only two classes i.e. walking and running.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change the final layer for our purpose \n",
    "output_layer = DenseLayer(net['fc7-1'], num_units=2, nonlinearity=softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a directory to save the results\n",
    "savepath = os.path.join(\"results\", \"ucf\"+\"-%04d\"%(2))    \n",
    "if not os.path.isdir(savepath):\n",
    "    os.makedirs(savepath)\n",
    "elif os.path.isdir(savepath):\n",
    "    print \"Directory of results already exists. Please delete the directory and rerun the command.\"     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the training parameters. Set the learning rate to be low as we do not want to drastically change \n",
    "# the weights of the pre-trained model. \n",
    "method = \"momentum\"\n",
    "lr = 0.00001 \n",
    "lr_decay = 0.5 \n",
    "momentum = 0.5 \n",
    "ephs = 6 \n",
    "bth = 8 \n",
    "neph_dcy = 3 \n",
    "reg = 0.00001\n",
    "train_db = \"./data/ucf-train.lmdb/\"\n",
    "val_db = \"./data/ucf-val.lmdb/\"\n",
    "vid_shape = (16,112,112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_var = dtensor5('inputs')\n",
    "target_var = T.ivector('targets') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prediction and loss functions\n",
    "prediction = lasagne.layers.get_output(output_layer,input_var)\n",
    "loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "loss = loss.mean()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add regularization\n",
    "weightsl2 = regularize_network_params(output_layer,l2)\n",
    "loss += weightsl2*reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get all the parameters\n",
    "params = lasagne.layers.get_all_params(output_layer, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_shared = theano.shared(lasagne.utils.floatX(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select the update method\n",
    "if method == 'sgd':\n",
    "    updates = lasagne.updates.sgd(loss, params, learning_rate=lr_shared)\n",
    "    print \"Training by stochastic gradient descent...\"\n",
    "elif method == 'momentum':\n",
    "    updates = lasagne.updates.momentum(loss, params, learning_rate=lr_shared, momentum=momentum)\n",
    "    print \"Training by stochastic gradient descent with momentum...\"\n",
    "elif method == 'nesterov_momentum':\n",
    "    updates = lasagne.updates.nesterov_momentum(loss, params, learning_rate=lr_shared, momentum=momentum)\n",
    "    print \"Training with nesterov momentum...\"\n",
    "elif method == 'rmsprop':\n",
    "    updates = lasagne.updates.rmsprop(loss, params, learning_rate=lr_shared)\n",
    "    print \"Training with rmsprop...\"\n",
    "else: \n",
    "    raise NotImplemented(\"Optimization method %s not implemented\"%method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test function\n",
    "test_prediction = lasagne.layers.get_output(output_layer,input_var, deterministic=True)\n",
    "test_loss = lasagne.objectives.categorical_crossentropy(test_prediction,target_var)\n",
    "test_loss = test_loss.mean()\n",
    "test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var),dtype=theano.config.floatX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize the train function\n",
    "train_fn = theano.function([input_var, target_var], loss, updates=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize the validation function\n",
    "val_fn = theano.function([input_var, target_var], [test_loss, test_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initializa the data objects for train and validation\n",
    "fetcher_train = DataFetcher(train_db, vid_shape, bth)\n",
    "fetcher_val = DataFetcher(val_db, vid_shape, bth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "# Finally, launch the training loop.\n",
    "print(\"Starting training...\")\n",
    "best_val_acc = 0.0\n",
    "for epoch in range(ephs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    crossed_epoch_train = False\n",
    "    while crossed_epoch_train == False:        \n",
    "        X,y,crossed_epoch_train = fetcher_train.load_data() \n",
    "        inputs, targets = X,y\n",
    "        targets = targets.astype('int32')\n",
    "        train_err += train_fn(inputs, targets)\n",
    "        train_batches += 1\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_err = 0\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    crossed_epoch_val = False\n",
    "    while crossed_epoch_val == False:\n",
    "        X,y, crossed_epoch_val = fetcher_val.load_data()\n",
    "        inputs, targets = X,y \n",
    "        targets = targets.astype('int32')\n",
    "        err, acc = val_fn(inputs, targets)\n",
    "        val_err += err\n",
    "        val_acc += acc\n",
    "        val_batches += 1\n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, ephs, time.time() - start_time))\n",
    "    print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "        val_acc / val_batches * 100)) \n",
    "        \n",
    "    if (epoch%neph_dcy == 0):\n",
    "        new_lr = lr_shared.get_value() * lr_decay       \n",
    "        print \"new learning rate: %f\"%new_lr\n",
    "        lr_shared.set_value(lasagne.utils.floatX(new_lr))            \n",
    "\n",
    "    if ((val_acc/val_batches) > best_val_acc):\n",
    "        print \"***Best model so far***\"\n",
    "        best_val_acc = (val_acc/val_batches)\n",
    "        np.savez(os.path.join(savepath,'best_model.npz'), *lasagne.layers.get_all_param_values(output_layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
